# Loka Inference Server
# Optimized for serving the trained model

FROM nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1

# Install minimal dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# Install miniforge
ENV CONDA_DIR=/opt/conda
RUN curl -sL https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh -o /tmp/miniforge.sh \
    && bash /tmp/miniforge.sh -b -p $CONDA_DIR \
    && rm /tmp/miniforge.sh
ENV PATH=$CONDA_DIR/bin:$PATH

WORKDIR /app

# Install production dependencies only
RUN conda install -y -c conda-forge \
    python=3.11 \
    numpy \
    scipy \
    astropy \
    jplephem \
    && conda clean -afy

# Install PyTorch (inference optimized)
RUN pip install --no-cache-dir \
    torch>=2.0 \
    transformers>=4.40 \
    accelerate \
    safetensors \
    vllm \
    fastapi \
    uvicorn[standard]

# Copy application
COPY src/ src/
COPY pyproject.toml .
RUN pip install -e .

# Copy model (or mount at runtime)
# COPY models/ /models/

ENV LOKA_MODEL_DIR=/models

EXPOSE 8000

CMD ["uvicorn", "loka.serve:app", "--host", "0.0.0.0", "--port", "8000"]
